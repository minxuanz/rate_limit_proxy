# Rate Limit Proxy

一个基于 Rust + Axum 的轻量级速率限制反向代理服务。

## 功能特性

- **反向代理**: 将请求转发到后端服务
- **并发限制**: 限制同时处理的请求数量（默认 5 个并发）
- **轻量级**: 使用 Rust 编写，性能高效
- **易于部署**: 支持 Docker 部署

## 什么是 API 网关？

API 网关（如 Kong、Nginx、Envoy）是位于客户端和后端服务之间的**中间层**，主要作用包括：

### 核心功能

| 功能 | 说明 |
|------|------|
| **反向代理** | 接收客户端请求，转发到后端服务 |
| **负载均衡** | 将流量分发到多个后端实例 |
| **限流限速** | 防止后端服务被过载请求压垮 |
| **认证授权** | 统一处理 API 密钥、JWT 验证等 |
| **SSL/TLS 终止** | 处理 HTTPS 加密解密 |
| **缓存** | 缓存常用响应，减少后端压力 |
| **监控日志** | 记录请求日志，便于分析 |

### 为什么需要网关？

```
┌─────────┐     ┌──────────┐     ┌─────────┐
│ 客户端  │────▶│ API 网关 │────▶│ 后端服务 │
└─────────┘     └──────────┘     └─────────┘
                    │
                    ▼
            ┌───────────────┐
            │ • 限流保护      │
            │ • 认证检查      │
            │ • 日志记录      │
            │ • 负载均衡      │
            └───────────────┘
```

**优势**：
- **安全性**: 隐藏后端服务真实地址
- **高可用**: 单点故障不影响整体服务
- **可扩展**: 轻松添加新的后端服务
- **统一管理**: 集中配置认证、限流策略

## 快速开始

### 本地运行

```bash
# 克隆项目
git clone <repo-url>
cd rate_limit_proxy

# 运行
cargo run
```

服务将启动在 `http://127.0.0.1:3000`

> **为什么代码用 `0.0.0.0` 但显示 `127.0.0.1`？**
> 
> - **`0.0.0.0`**（绑定地址）：表示监听**所有网络接口**，允许从任何 IP 访问（包括 Docker 容器外部）。这是服务器部署的标准做法。
> - **`127.0.0.1`**（访问地址）：是本地回环地址，仅用于本机测试。打印这个是为了告诉你本地测试时用这个地址。
> 
> 如果绑定 `127.0.0.1`，Docker 容器外部将无法访问服务！

### 使用 Docker 部署

#### 1. 构建镜像

```bash
docker build -t rate-limit-proxy .
```

#### 2. 运行容器

```bash
# 前台运行
docker run -p 3000:3000 rate-limit-proxy

# 后台运行
docker run -d -p 3000:3000 --name rate-limit-proxy rate-limit-proxy

# 查看日志
docker logs -f rate-limit-proxy
```

#### 3. 验证服务

```bash
# 测试代理转发（默认转发到 httpbin.org）
curl http://localhost:3000/get

# 测试并发限制（开多个终端同时执行）
curl http://localhost:3000/delay/5
```

### Docker Compose 部署（推荐）

创建 `docker-compose.yml`:

```yaml
version: '3'
services:
  proxy:
    build: .
    ports:
      - "3000:3000"
    restart: unless-stopped
    # 环境变量（后续可扩展）
    environment:
      - RUST_LOG=info
```

运行：

```bash
docker-compose up -d
```

## 使用场景

### 场景 1：保护后端 API

```
用户 ──▶ 网关（限流）──▶ 你的后端服务
```

防止突发流量打垮后端服务。

### 场景 2：多服务路由

```
         ┌─▶ 用户服务
用户 ──▶ 网关 ─┼─▶ 订单服务
         └─▶ 支付服务
```

通过一个入口访问多个后端服务。

### 场景 3：API 聚合

```
用户 ──▶ 网关 ──▶ 同时调用多个服务 ──▶ 合并返回
```

减少前端请求次数。

## 配置说明

当前配置：

- **监听端口**: `3000`
- **后端服务**: `https://httpbin.org`
- **并发限制**: 5 个请求

## 技术栈

- **Rust**: 系统编程语言
- **Axum**: Web 框架
- **Tower**: 中间件框架（提供限流功能）
- **Reqwest**: HTTP 客户端

## 许可证

MIT
